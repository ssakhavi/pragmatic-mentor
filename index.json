[{"categories":["Machine Learning"],"content":"Differences between MLOps and ML-as-a-Service","date":"2023-02-01","objectID":"/mlaas-vs-mlops/","tags":["MLOps","ML-as-as-Service"],"title":"MLaaS vs MLOps","uri":"/mlaas-vs-mlops/"},{"categories":["Machine Learning"],"content":"I watched this interesting video regarding the differences of MLOps (e.g. Train, Serve, Monitor your own model) vs ML-as-a-Service (e.g. Foundation Models). MLOps vs ML-As-Service // Jill Chase and Manmeet Gujral // MLOps Podcast #143 clip - YouTube These are some interesting learning points: MLaaS tend to be more B2C and MLOps is mainly B2B Foundation Models have pushed the MLOps Frameworks to emphasize on the software’s ability to perform fine-tuning MLOps revenue generation is not as fast as MLaaS but the contracts and projects are bigger MLOps tends to lean towards providing for instances of Proprietary Data. ","date":"2023-02-01","objectID":"/mlaas-vs-mlops/:0:0","tags":["MLOps","ML-as-as-Service"],"title":"MLaaS vs MLOps","uri":"/mlaas-vs-mlops/"},{"categories":["Machine Learning"],"content":"This is my conversation with OpenAI’s ChatGPT. I want to clarify I have no intention of using this technology for monotization. I’ve used it for generating knowledge and nothing else. ","date":"2022-12-02","objectID":"/functional-programming-in-ml/:0:0","tags":["Functorch","JAX","ChatGPT","OpenAI"],"title":"Functional Frameworks in Machine Learning","uri":"/functional-programming-in-ml/"},{"categories":["Machine Learning"],"content":"Functional Frameworks Are a Thing Q: I’ve been noticing machine learning frameworks such as JAX and functorch have been adopting functional programming paradigms. Is this true? Yes, it’s true that some machine learning frameworks are adopting functional programming paradigms. This is because functional programming can help make it easier to write code that is concise, modular, and reusable, which can be useful when working on large machine learning projects. Additionally, functional programming can help make it easier to parallelize code and perform automatic differentiation, which are important capabilities for many machine learning tasks. JAX, for example, is a functional programming framework for machine learning that is built on top of the popular NumPy library. It allows users to write code using functions and automatic differentiation, and it can run on GPUs and other hardware accelerators. Functorch is another example of a machine learning framework that uses functional programming. It is built on top of the popular PyTorch library and allows users to write code using functional programming constructs. Overall, the use of functional programming in machine learning is still relatively new, but it is gaining traction as a way to improve the efficiency and modularity of machine learning code. ","date":"2022-12-02","objectID":"/functional-programming-in-ml/:1:0","tags":["Functorch","JAX","ChatGPT","OpenAI"],"title":"Functional Frameworks in Machine Learning","uri":"/functional-programming-in-ml/"},{"categories":["Machine Learning"],"content":"What Are Per Sample Gradients? Q: What is per sample gradients and why do these frameworks help with the computation of per sample gradients? Per-sample gradients are gradients that are calculated for each individual sample in a dataset, rather than for the entire dataset as a whole. This can be useful for tasks such as learning with very large datasets, where it may not be possible to calculate gradients for the entire dataset at once. Some machine learning frameworks, such as JAX and Functorch, are designed to make it easier to calculate per-sample gradients. These frameworks typically use functional programming constructs, such as higher-order functions and automatic differentiation, to allow users to write code that can calculate gradients for individual samples in a concise and modular way. For example, in JAX, users can write a function that calculates the gradient of a model’s output with respect to its inputs, and then use this function to calculate the gradient for each sample in a dataset. This can be done in a parallelized and efficient manner, which can make it much easier to work with large datasets. In general, the ability to calculate per-sample gradients can be important for many machine learning tasks, and frameworks like JAX and Functorch can make it easier to do so. ","date":"2022-12-02","objectID":"/functional-programming-in-ml/:2:0","tags":["Functorch","JAX","ChatGPT","OpenAI"],"title":"Functional Frameworks in Machine Learning","uri":"/functional-programming-in-ml/"},{"categories":["Machine Learning"],"content":"Why Would I Want to Use These Frameworks? Q: For a person who is using Pytorch for training models, would they benefit in switching to Functorch? Whether a person who is using PyTorch for training models would benefit from switching to Functorch would depend on a number of factors, including their specific goals and the specific features of the two frameworks. Functorch is a functional programming framework built on top of PyTorch, so it offers many of the same capabilities as PyTorch, such as support for deep learning and neural networks. However, Functorch also adds functional programming constructs, such as higher-order functions and automatic differentiation, which can make it easier to write concise, modular, and reusable code. If a person is already familiar with PyTorch and is happy with the features and capabilities it offers, then switching to Functorch may not necessarily provide any significant benefits. However, if a person is looking for a way to improve the efficiency and modularity of their machine learning code, or if they are interested in using functional programming techniques in their work, then Functorch might be a good option to consider. Ultimately, whether a person would benefit from switching from PyTorch to Functorch would depend on their specific needs and goals. It might be worth exploring both frameworks to see which one works best for a particular project or use case. ","date":"2022-12-02","objectID":"/functional-programming-in-ml/:3:0","tags":["Functorch","JAX","ChatGPT","OpenAI"],"title":"Functional Frameworks in Machine Learning","uri":"/functional-programming-in-ml/"},{"categories":["Machine Learning"],"content":"Can You Give Me an Example? Here is an example of a simple machine learning model written in vanilla PyTorch: import torch # Define a model with a single linear layer class LinearModel(torch.nn.Module): def __init__(self, input_size, output_size): super().__init__() self.linear = torch.nn.Linear(input_size, output_size) def forward(self, x): return self.linear(x) # Create an instance of the model model = LinearModel(10, 1) # Generate some random input data x = torch.randn(100, 10) # Use the model to make predictions on the input data y_pred = model(x) # Calculate the loss loss = torch.nn.functional.mse_loss(y_pred, y) # Backpropagate the loss to calculate the gradients loss.backward() # Update the model parameters optimizer = torch.optim.SGD(model.parameters(), lr=0.01) optimizer.step() Here is the same model written using Functorch: import functorch as fc # Define a model with a single linear layer using Functorch's functional API def linear_model(input_size, output_size): def forward(x): linear = fc.Linear(input_size, output_size) return linear(x) return fc.Model(forward) # Create an instance of the model model = linear_model(10, 1) # Generate some random input data x = fc.randn(100, 10) # Use the model to make predictions on the input data y_pred = model(x) # Calculate the loss loss = fc.mse_loss(y_pred, y) # Backpropagate the loss to calculate the gradients loss.backward() # Update the model parameters optimizer = fc.SGD(model.parameters(), lr=0.01) optimizer.step() In this example, the model is defined using Functorch’s functional API, which allows us to write the model as a function that takes inputs and returns outputs. This can make the code more concise and easier to read than the PyTorch version, which uses object-oriented programming. Additionally, Functorch automatically calculates gradients and performs backpropagation when loss.backward() is called, which can make the code even simpler and more modular. ","date":"2022-12-02","objectID":"/functional-programming-in-ml/:4:0","tags":["Functorch","JAX","ChatGPT","OpenAI"],"title":"Functional Frameworks in Machine Learning","uri":"/functional-programming-in-ml/"},{"categories":["Machine Learning"],"content":"A More Complicated Example Sure, here is a more complicated example of a machine learning model written using Functorch: import functorch as fc # Define a convolutional neural network using Functorch's functional API def convnet(input_size, num_classes): def forward(x): # Apply a sequence of convolutional and pooling layers x = fc.Conv2d(x, 32, kernel_size=3, padding=1) x = fc.ReLU(x) x = fc.MaxPool2d(x, kernel_size=2) x = fc.Conv2d(x, 64, kernel_size=3, padding=1) x = fc.ReLU(x) x = fc.MaxPool2d(x, kernel_size=2) # Flatten the output of the convolutional layers x = x.view(x.size(0), -1) # Apply a sequence of fully-connected layers x = fc.Linear(x, 512) x = fc.ReLU(x) x = fc.Linear(x, num_classes) # Return the logits return x return fc.Model(forward) # Create an instance of the model model = convnet(input_size=(3, 32, 32), num_classes=10) # Generate some random input data x = fc.randn(100, 3, 32, 32) # Use the model to make predictions on the input data y_pred = model(x) # Calculate the loss loss = fc.cross_entropy_loss(y_pred, y) # Backpropagate the loss to calculate the gradients loss.backward() # Update the model parameters optimizer = fc.SGD(model.parameters(), lr=0.01) optimizer.step() In this example, we define a convolutional neural network using Functorch’s functional API. This allows us to write the model as a function that takes inputs and returns outputs, and it allows us to use functional programming constructs such as higher-order functions and automatic differentiation. This can make the code more concise and easier to read than if we were to define the model using object-oriented programming, as we would have to do in PyTorch. Additionally, Functorch automatically calculates gradients and performs backpropagation when loss.backward() is called, which can make the code even simpler and more modular. This can be particularly useful when working with complex neural network architectures, as it can help reduce the amount of boilerplate code that needs to be written. ","date":"2022-12-02","objectID":"/functional-programming-in-ml/:5:0","tags":["Functorch","JAX","ChatGPT","OpenAI"],"title":"Functional Frameworks in Machine Learning","uri":"/functional-programming-in-ml/"},{"categories":["Machine Learning"],"content":"Making My Conversation into a Blog Post? Q: How would our conversation until here look like as a blog post? Here is an example of how our conversation until now could be written as a blog post: Title: Functional Programming in Machine Learning: An Introduction to Functorch and JAX Functional programming is a programming paradigm that focuses on the use of functions to model computations and data. In recent years, functional programming has been gaining popularity in the machine learning community, with some frameworks, such as Functorch and JAX, adopting functional programming paradigms. Functorch is a functional programming framework built on top of PyTorch, a popular deep learning library. It allows users to write code using functional programming constructs, such as higher-order functions and automatic differentiation, which can make it easier to write concise, modular, and reusable code. JAX is another functional programming framework for machine learning, built on top of the NumPy library. Like Functorch, it allows users to write code using functional programming constructs and to perform automatic differentiation. Additionally, JAX can run on GPUs and other hardware accelerators, which can make it easier to scale up machine learning code and work with large datasets. The use of functional programming in machine learning is still relatively new, but it is gaining traction as a way to improve the efficiency and modularity of machine learning code. If you are interested in functional programming and machine learning, then learning about Functorch and JAX could be a useful addition to your skillset. ","date":"2022-12-02","objectID":"/functional-programming-in-ml/:6:0","tags":["Functorch","JAX","ChatGPT","OpenAI"],"title":"Functional Frameworks in Machine Learning","uri":"/functional-programming-in-ml/"},{"categories":["PKM"],"content":"What do you store and how do you store it so later you can retrieve it ? ","date":"2022-11-17","objectID":"/information-proc-org-rec/:0:0","tags":["Knowledge Management"],"title":"Information- Processing, Organization and Retrieval","uri":"/information-proc-org-rec/"},{"categories":["PKM"],"content":"What am I sharing ? I have a problem with finding the right information from the raw data I receive, organizing that information and also being able to retrieve the information in an optimal manner. Let me give you an example to clarify a bit more. ","date":"2022-11-17","objectID":"/information-proc-org-rec/:1:0","tags":["Knowledge Management"],"title":"Information- Processing, Organization and Retrieval","uri":"/information-proc-org-rec/"},{"categories":["PKM"],"content":"Example Scenario: Daily Standup Scenario: I have a standup meeting with my team almost every day. These standups are either async or face-to-face. I play the role of “team lead”/ “coach” in this team. The raw data: The updates that my teammates share with me. The challenge: What should I be taking away from my conversation with the team, how should I organize it, and also, how do I retrieve it and use it later. In the case of a standup, you might say that all of the information I need comes naturally from the format that a standup is arranged. You’re right. a typical standup consists of 3 prompts asked from each individual: What were you working on? What are you planning on working on? Do you have anything blocking your progress? These are straightforward. But the data shared can be redundant, not for me, or it might more processing. I need to find the answer for this question for myself: When I know the answers to the these prompts, from each individual developer, how will it help me in the role that I’m playing for the current project and also, future projects I have? The “future project” part is something very important for me: I don’t want to forget the important learning points that I gather from my conversations with my team members and also, I need to identify action items for progressing the current project as well. The daily standup can be considered as the more simpler meeting I have with my colleagues. Technical discussions, code reviews, sprint reviews, sprint planning, researching code repositories, reading articles and other events and “rituals” all are inputs in my system and I need to make sense of them and use it for not only projects but also for my own professional development. Given the confusion I’m facing, I have found opinions and ideas from knowledge workers and productivity experts that are very useful and in order to articulate my thoughts and whatever I have learned, I have decided to write some articles. I hope these can benefit whoever is lost in the age of information overload like me and wants to make sense of the world around. I want to make it obvious that I won’t writing from scratch and I’ll be compiling knowledge from other brilliant minds in order to reach a conclusion or process for myself. ","date":"2022-11-17","objectID":"/information-proc-org-rec/:1:1","tags":["Knowledge Management"],"title":"Information- Processing, Organization and Retrieval","uri":"/information-proc-org-rec/"},{"categories":["PKM"],"content":"Another Example: Strategies for Organization There was a video posted by [[Nicole van der Hoeven]] recently on the topic of information management. She was sharing a information organization strategy called “LATCH” and how she uses concepts such as metadata, tags, links and folders in Obsidian to implement this strategy. “LATCH” stands for Location, Alphabet, Time, Category and Hierarchy. This strategy was introduced in the book “Information Anxiety” and you can see an article about it here. [[Nick Milo]], in his November 9th 2022 newsletter, also discussed how the above strategy is redundant and he proposed a new strategy called “STIR”: Strategy, Time, Importance, Relatedness. Nick gives an example of how to organize a spatula in the kitchen: What about the spatula in the kitchen? Where would you map that onto STIR? Time seems less needed than Space and Relatedness. You need to know where it is. If you’re good, you’ve placed it next to the stove, with other spatula’s and things you’ll need next to the stove. And if you have to flip eggs in a hurry, that spatula’s Importance grows in a hurry! But after breakfast, the spatula’s relative Importance drops. Then Nick mentions the following: This is a reminder that knowledge is fluid. Don’t try to overstructure your knowledge with so much metadata and formatting that things grind to a halt. Things like “Importance” are fluid, and spending all my time adjusting an Importance score to thousands of notes is a form of insanity I choose to avoid. This last point, knowledge is fluid is very important. If something is so fluid, how do we organize it now so we can retrieve the knowledge later? After we’ve processed our raw data, and we’ve managed to extract information or knowledge out of it, we need to organize it in a way that we are able to retrieve it for future use. The fluid nature of knowledge leads to instances that make it difficult to identify how the data should be organized: Should we organize via a set number of folders and Hierarchy (like [[Tiago Forte]]’s P.A.R.A. or [[Nick Milo]]’s ACCESS)? Should we be flat and just use tags? Should our tags be limited (resembling folders), multi-dimensional? In any of the above methods, how do we make sure that our note goes to the “right” place? an by “right” we mean in a way that we can retrieve it without guessing. ","date":"2022-11-17","objectID":"/information-proc-org-rec/:1:2","tags":["Knowledge Management"],"title":"Information- Processing, Organization and Retrieval","uri":"/information-proc-org-rec/"},{"categories":["PKM"],"content":"Series Writing Direction I’m planning on writing a series of articles on the topics of information processing, information organization and information retrieval. These articles are inspired by the work of smart people and building on their shoulders. The main 3 articles will be: [[Information \u0026 Its Processing]] [[Information \u0026 Its Organization]] [[Information \u0026 Its Retrieval]] Hopefully, I’ve shared something useful with you in this article and made you think or maybe, realize that you’re in a better place than me. Siavash ","date":"2022-11-17","objectID":"/information-proc-org-rec/:2:0","tags":["Knowledge Management"],"title":"Information- Processing, Organization and Retrieval","uri":"/information-proc-org-rec/"},{"categories":null,"content":"In my last post, I was shared what my concerns were regarding software development and what my role as a Tech Lead should look at AISG. Today, I had an awesome find! ","date":"2021-11-24","objectID":"/software-eng-at-google/:0:0","tags":["Software Engineering","Book"],"title":"Found It!: Software Engineering at Google","uri":"/software-eng-at-google/"},{"categories":null,"content":"One thing led to another I was looking at my youtube subscriptions, and I saw video posted on the “Dev Interrupted” channel. If you aren’t subscribed to it, I highly recommend it. I recall I found the channel when Luca Rossi, the owner of the amazing “Refactoring” newsletter, mentioned it in one of the issues of his newsletter (Thanks Luca!). The video, titled Evaluating and Understanding Constraints in Software Engineering was actually a clip from a podcast interview in June 2021. The title of the video didn’t click with me at first. When I opened it and listened. They were talking about constraints that are needed during software engineering (something I personally believe in). I searched the names of the interviewees and found out they were the authors of the book “Software Engineering at Google”. I can’t tell you how many times I’d seen this book on different websites and how much I wanted to read it. Unfortunately, I would always de-prioritize it on my reading list. I went to the book on my O’Reilly account, opened the TOC and then, my jaw dropped. The TOC was almost all of the things I wrote down in my previous post and more. To my amazement, the book is also shared for free on their website. ","date":"2021-11-24","objectID":"/software-eng-at-google/:1:0","tags":["Software Engineering","Book"],"title":"Found It!: Software Engineering at Google","uri":"/software-eng-at-google/"},{"categories":null,"content":"How am I going to go from here? This new finding is very precious. In my coming posts, I’ll be using elements of the book and also, other books that I have access to or purchased. My main goal would be to define the processes and practices from the point of view of a Machine Learning Engineer and Tech Lead @AISG. ","date":"2021-11-24","objectID":"/software-eng-at-google/:2:0","tags":["Software Engineering","Book"],"title":"Found It!: Software Engineering at Google","uri":"/software-eng-at-google/"},{"categories":null,"content":"It’s been a year since I joined AI Singapore and I’m grateful for the experience so far. I’ve been on a few projects up until now and gathered a lot of experience. My journey, however, is far from over and I have many things to learn. ","date":"2021-11-22","objectID":"/being-a-tech-lead-at-aisg/:0:0","tags":["Tech Lead","Mentorsip","Experience"],"title":"Being a Tech Lead at AISG","uri":"/being-a-tech-lead-at-aisg/"},{"categories":null,"content":"What am I suppose to do? I remember when I started my job, I asked my supervisor: What is my role as a “Senior Engineer”? Am I a “Tech Lead”? Am I an “Engineering Manager”? What am I suppose to be doing? At that time, I shared with him a great blog post by Pat Kua on the topic of different types of engineering managers and he pointed out that my responsibility is to be Tech Lead EM for the project. At the time, it was kind of a relief for me: I knew the “title” of the role I needed to play. But, to be honest, it took a year for the actual responsibilities to sink in. I think that’s learning on the job. I’m going to be starting a new project very soon, and I decided to have a fresh look at my responsibilities as a Tech Lead in the 100E projects. I plan on writing a series of posts on the topic and hopefully, by doing so, organize my own mind as well. ","date":"2021-11-22","objectID":"/being-a-tech-lead-at-aisg/:1:0","tags":["Tech Lead","Mentorsip","Experience"],"title":"Being a Tech Lead at AISG","uri":"/being-a-tech-lead-at-aisg/"},{"categories":null,"content":"A Tech Lead, an EM and a Mentor Before I jump into some of the aspects of being a Tech Lead that I’ve understood, I think it’s best I clarify why the “Tech Lead EM” (TLEM from now on) isn’t the exact stereotype that describes my job. Yes, I am the TLEM but first and foremost, I’m a mentor. Let me explain. When a person enrolls to the AI Singapore Apprenticeship Program (AIAP), they are looking for a fresh start. They’re looking to upskill themselves and understand the world of Machine Learning (ML). They want to learn the ropes and see how a project is carried on from start to finish. When they choose to do a 100E Project, they’ve decided on learning about ML while doing a industrial real-life projects. This complicates matters. As the person leading the project: I have to rely on the apprentices joining my project to design and develop and at the same time, teach them and guide them in an area that they’ve had minimal exposure to. I have to answer to the client/project’s sponsor who is relying on me for an ML product to be passed to them and also, I have to make sure that the apprentices have learned enough to be able to carry out their own projects in the future. There is a need for right blend of guiding, teaching, hand-holding, management, and software development. If I make decisions on the project, I need to explain how I reached the decision. If I design, I need to help the apprentices understand what details I’ve considered when ending up with the design. It’s not only about how fast and good you develop. It’s also about how much you’re able to convey experiences as well. ","date":"2021-11-22","objectID":"/being-a-tech-lead-at-aisg/:2:0","tags":["Tech Lead","Mentorsip","Experience"],"title":"Being a Tech Lead at AISG","uri":"/being-a-tech-lead-at-aisg/"},{"categories":null,"content":"Practices The following are just a list of things that I’ve decided to consider for the new project. Although I’ve adopted the practices in my previous projects, but I’ve come to realize that some of them need more attention this time round. (Note: This list is going to grow.) ","date":"2021-11-22","objectID":"/being-a-tech-lead-at-aisg/:3:0","tags":["Tech Lead","Mentorsip","Experience"],"title":"Being a Tech Lead at AISG","uri":"/being-a-tech-lead-at-aisg/"},{"categories":null,"content":"Management Processes Frequent 1:1s Meeting Note-Taking (Mainly Sprint Reviews) Frequent meetings with sponsors/clients for clarifying design decisions Technical Sessions Stand-ups Motivation ","date":"2021-11-22","objectID":"/being-a-tech-lead-at-aisg/:3:1","tags":["Tech Lead","Mentorsip","Experience"],"title":"Being a Tech Lead at AISG","uri":"/being-a-tech-lead-at-aisg/"},{"categories":null,"content":"Software Development Processes Code Reviews Pair Programming Branching Strategies Coding Style Pre-commit Hooks Document-Driven Design Design/Technical Sessions Functional Thinking/Programming Machine Learning Code Testing/Validation Error Analysis Error Visualization Automated Tests ","date":"2021-11-22","objectID":"/being-a-tech-lead-at-aisg/:3:2","tags":["Tech Lead","Mentorsip","Experience"],"title":"Being a Tech Lead at AISG","uri":"/being-a-tech-lead-at-aisg/"},{"categories":null,"content":"Mentorship Processes Continuous Learning of Agile Development Practices I will be writing more about each of the items above and link the related posts. ","date":"2021-11-22","objectID":"/being-a-tech-lead-at-aisg/:3:3","tags":["Tech Lead","Mentorsip","Experience"],"title":"Being a Tech Lead at AISG","uri":"/being-a-tech-lead-at-aisg/"},{"categories":null,"content":"How breaking the code on purpose can lead to learning where in the code there are problems.","date":"2020-11-25","objectID":"/2020-11-25-breaking-to-learn/","tags":["ML Architect","Experience"],"title":"Breaking the Code to Learn","uri":"/2020-11-25-breaking-to-learn/"},{"categories":null,"content":"I’ve started a new job at AI Singapore. The nature of the job is in a way that I have to mentor people and guide them to be better AI Engineers. That’s why I think my blog posts will be more relevant and useful. Today, I want to touch upon a topic that came to my mind when I was thinking about how to teach people whether there ML system is robust enough or not. When I was in my PhD, I would browse around to learn new stuff and one of the most amazing website I came across to learn new programming languages was “Learn X the Hard Way”. At that time X was C for me: CUDA had just gained popularity and because CUDA is mainly written in C and was keen in understanding parallel programming on GPUs, I decided to learn some C via the mentioned website. The website has changed since then (link) and most of the material which were free need to be purchased now. The way that the author of the learning course would teach the language was ineteresting: First, he would introduce a concept and explain how that concept is used for the C language. But later, he would ask to modify different places of the code and make the code break. This breaking of the code would result in an error message. By asking to break the code, the learners would be able to identify error messages corresponding to different problems that would be raised in different situations. Now, When I was thinking about robustness in machine learning and how to make sure the code is written in a way that it doesn’t crash, I came up with this solution in my mind: What if we modify some parts of the configuration or the data to see whether the pipeline is working or not and whether the different parts of the code have good handling of unexpected inputs of configurations. You could say that this sounds a lot like testing. I would say: yes! usually for test we check the functionality and whether for a certain input, the output is okay. Eventually, breaking the code will lead to writing tests and when you become more experienced, you know what tests you need to write for your code. Also, you might want to look at this as an attack on the network to check whether the code has covered the different scenarios of the configuration and data input. Let’s talk about an example: One of the mistakes that I have made many times, during my PhD and my KK days, is the matter of reading data based on a certain pattern ( i.e. asusming the the files are in sequence). This isn’t true in most of the times. One way to break the code in this case is to remove a data point manually and see if the data pipeline still works. Actually, I’ve realized that pytorch-lightning does some kind of validation before it starts training the data to see whether the config, input and the model match. Takeaway: Sometimes you need to break the code to understand the problem and design your code in a better way. Don’t write your code and assume because it’s working, you don’t have any bugs. Bugs won’t show if you don’t give your code a bit of a shake. ","date":"2020-11-25","objectID":"/2020-11-25-breaking-to-learn/:0:0","tags":["ML Architect","Experience"],"title":"Breaking the Code to Learn","uri":"/2020-11-25-breaking-to-learn/"},{"categories":null,"content":"The challenge of making decisions with the existence of different tools","date":"2020-06-30","objectID":"/2020-06-30-challenge-decision-making/","tags":["ML Architect","Tools","Decisions"],"title":"Challenge: Decision Making","uri":"/2020-06-30-challenge-decision-making/"},{"categories":null,"content":"In this blog I’m going to discuss one of the most difficult challenge that any architect will come across in their path to becoming professional: deciding on design and toold choices. For myself, this challenge reoccurs more and more often becuase of my own tendancy to making sure that my design is right and that I’m using the right tools. Maybe it’s better that I delve into what I mean with an example. ","date":"2020-06-30","objectID":"/2020-06-30-challenge-decision-making/:0:0","tags":["ML Architect","Tools","Decisions"],"title":"Challenge: Decision Making","uri":"/2020-06-30-challenge-decision-making/"},{"categories":null,"content":"Choosing a high level PyTorch tool It was around a two months ago when I was given new data to work with and I was tasked to train a segmentation model on the data. The task was simple: we have class A which is our desired class and everything else is background. This seems very simple and straightforward until a person like me starts thinking about how I can make the whole thing in the best way possible. I had done this experiment before a year back and since then, I knew there were new tools that could be used to bring more “structure” into my code. So I started searching. After some searching I came across a few frameweorks which are built on top of PyTorch and are designed to make life easier for those who don’t want to have a lot of boilerplate code. You can find almost all of them in the PyTorch EcoSystem page. After finding these amazingly well-designed frameworks, I had to make the tough decision: which one should I use. ","date":"2020-06-30","objectID":"/2020-06-30-challenge-decision-making/:1:0","tags":["ML Architect","Tools","Decisions"],"title":"Challenge: Decision Making","uri":"/2020-06-30-challenge-decision-making/"},{"categories":null,"content":"Narrowing it down Here it got a bit tricky: I was trying to find something to use which was easy to plug into my current code and at the same time, had structure. My philosophy is that a good framework is a framework which enforces structure. That’s why after looking at the examples and source code, I narrowed down my options to two: PyTorch Lightning (PL) and Catalyst. Initially, I had a tough time; Both frameworks are amazing and they cover a lot of the boilerplate code and give some degrees of autmation. Catalysy even has a example on how to use their framework for segmentation. But in order to come up with a decision, I decided to to implement the segmentation algorithm in both frameworks. One of the things that was intriguing about PL and eventually led to me deciding on this framework, was the way it was implemented: The whole framework was a python class which needed its abstract methods to be populated based on the problem in hand. This was exactly what I was looking for. After populating the class (PL module), a simple method was executed with the intended parameters and logging methods. This really helps with making the training modular as possible, which is one of the needs for a flexible architecture. I saw this benefit when I tried mixing hydra with my PL code. It was supper easy because the parameter values were already being passed as a dicitonary and I just needed to pass them as DictConfig (the type of the Hydra parameter dictionary based on OmegaConf). Then I added MLFlow into the mix. This was another reason I selected PL: It had a built-in MLFlow logger. By adding MLFlow, I found a bug which most likely was spotted because of the use of Hydra and MLFlow together. This resulted in a PR. I really don’t know if it was a bug or not because it was possible that upgrading the versions of my python packages would solve the problem, but they updated the code in a way that solved it entirely. ","date":"2020-06-30","objectID":"/2020-06-30-challenge-decision-making/:2:0","tags":["ML Architect","Tools","Decisions"],"title":"Challenge: Decision Making","uri":"/2020-06-30-challenge-decision-making/"},{"categories":null,"content":"Takeaways My Takeaways from this experience: Believe in a philosophy or an ideal regarding how code should look like. Narrow down options by intially reading through the documents and sample code After narrowing down, impelement the raw version of your code in the options you have and see the benefits and caveats Don’t be shy to submit issues or PRs on GitHub (I submitted a PR, panicked and deleted my code and one of the owners asked that why I did that) Take care. ","date":"2020-06-30","objectID":"/2020-06-30-challenge-decision-making/:3:0","tags":["ML Architect","Tools","Decisions"],"title":"Challenge: Decision Making","uri":"/2020-06-30-challenge-decision-making/"},{"categories":null,"content":"The first post to descible why I started the blog","date":"2020-04-03","objectID":"/2020-04-03-the-beginning/","tags":["ML Architect"],"title":"The Beginning","uri":"/2020-04-03-the-beginning/"},{"categories":null,"content":"I really don’t know what title I can put on myself. Although, in my current comapny, I am considered to be the Lead AI Scientist but to be honest, I don’t know what that means. My background is machine learning and deep learning. I have worked on multiple aread of machine learning (some which I don’t have a paper). In my master’s thesis, I was using machine learning to differentiate between a special type of evoked potentials in the brain called the “Error Potential”. At that time, I was obssessed with orthogonality and especially when it came into a non-orthogonal space. When I entered my PhD in 2013, it was the year when the AlexNet came out and therefore, Deep Learning was the craze. There was no pytorch, but there was torch7. There was no tensorflow, but there was caffe. I needed to up my game and eventually, I got my PhD with torch7. Tensorflow was open-sourced just one year plus before I finished my PhD. Now, lonmg story short: I am a person that likes to think meta and design software. When I entered the production ML world, I didn’t know about design patterns, agile, kanban, XP, software architecture and many other concepts a person must know to do professional softare development. Comin to know about all these things, it hit my mind that what do I want to do for my career? Where do I see myself in a few years time. After some research and surfing the web, I came across an interesting paper “Machine Learning Architecture and Design Patterns”. This paper was a real eye-opener for me and I decided that maybe, this is the direction I want to go towards: becoming an Machine Learning Architect. Now as an architect, one of the first things is to understand is that what does an software architect do? and how do we translate the practices of software architecture design to machine learning problems. I’m hoping to shed more light on this. ","date":"2020-04-03","objectID":"/2020-04-03-the-beginning/:0:0","tags":["ML Architect"],"title":"The Beginning","uri":"/2020-04-03-the-beginning/"},{"categories":null,"content":"My name is Siavash (See-ya-vash) Sakhavi. Nice to meet you! I am Iranian, Married, Have two children, and live in Singapore. ","date":"0001-01-01","objectID":"/about/:0:0","tags":null,"title":"About Me","uri":"/about/"},{"categories":null,"content":"How would I describe myself? I’m a resourceful person due to reading and digesting of topic spanning from Software Engineering, to Machine Learning, to Project Management. I always like a new challenge and constantly try to learn and implement new technologies. For example, I’m interested in Functional Programming and Declerative Programming and how machine learning code can borrow the concepts. I question concepts and ways things are implemented and try to find better ways for them to work in the situation I have. ","date":"0001-01-01","objectID":"/about/:1:0","tags":null,"title":"About Me","uri":"/about/"},{"categories":null,"content":"Work Background ","date":"0001-01-01","objectID":"/about/:2:0","tags":null,"title":"About Me","uri":"/about/"},{"categories":null,"content":"AI Singapore (2020-Present) I am a Senior AI Engineer @ AI Singapore and Assistant Head for the 100E Program. My responsibilities are: Leading and Mentoring AIAP apprentices during 100E projects. Consulting and guiding the Pre-sales team for 100E project scoping Talent Development under the AIAP and AIDP programs Technical Writing for Knowledge Management Onboarding new engineers on the 100E team Some of the 100E Projects I’ve been involved in: Project Domain Model Types Detecting Nautical Objects from on-board cameras CV RCNN, YOLO Generating Narratives from News and Reports NLP Transformers Creating HD Maps from LIDAR Point-Cloud and RGB Images CV Similarity-Based Fault Detection and Prediction in IoT Sensor Data Signal Signal Modelling, CNN Open-set Audio Classification on Edge Devices Audio,CV CNN ","date":"0001-01-01","objectID":"/about/:2:1","tags":null,"title":"About Me","uri":"/about/"},{"categories":null,"content":"KroniKare (2017-2020) I was the founding engineer and Lead AI Scientist @ KroniKare, a start-up company focusing on AI solutions for wound analysis and management. I was working on the training, evaluation and deployment of machine learning/ deep learning models, on edge and on the cloud. I was also Product Manager and Developer for the KroniKare Data Collection and AI (KDCAI) Android Application. Skills and Achievements: Mentored apprentices under the AISG apprenticeship program (AIAP) Supervised students from Republic Polytechnic (RP) under there specialist diploma program Successfully completed POC trials at multiple healthcare institutes Actively involved as a product manager in the software project development. Trained hundreds of nurses for the use of the KroniKare wound scanner application Help with the implementation of ISO 13485 and IEC 62304. ","date":"0001-01-01","objectID":"/about/:2:2","tags":null,"title":"About Me","uri":"/about/"},{"categories":null,"content":"Acedemic Background I was a Biomedical Engineering (Bio-Electrics) student at Amirkabir university of technology during my bachelors. My Project Supervisor during this time was Dr.VahidReza Nafisi. My focus was designing and developing a system for recording and analyzing wrist pulse signals based on traditional Iranian medicine. For my masters I was at Sharif University of Technology under the supervision of Dr.Mohammad Bagher Shamsollahi, a guru in the field if Signal Processing and Time-Frequency Analysis. My project was designing a Error-Potential Based Task for BCI applications. For my PhD, I was part of at joint PhD program between A*STAR and NUS. I was mainly based in the Brain-Computer Interface Lab @ A*STAR. I was working under the supervision of Dr. Guan Cuntai and Dr. Yan Shuicheng. My thesis is on the application of Deep Learning Methods in Brain-Computer Interfaces. I also worked on Object Detection and Proposal Generation during my third year when I was stationed at the Learning and Vision Lab @NUS. ","date":"0001-01-01","objectID":"/about/:3:0","tags":null,"title":"About Me","uri":"/about/"}]