<!doctype html><html itemscope itemtype=http://schema.org/WebPage lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=2"><meta name=robots content="noodp"><title>Functional Frameworks in Machine Learning -</title><meta name=author content><meta name=author-link content><meta name=description content="This is my conversation with OpenAI&rsquo;s ChatGPT. I want to clarify I have no intention of using this technology for monotization. I&rsquo;ve used it for generating knowledge and nothing else.
Functional Frameworks Are a Thing Q: I&rsquo;ve been noticing machine learning frameworks such as JAX and functorch have been adopting functional programming paradigms. Is this true?
Yes, it&rsquo;s true that some machine learning frameworks are adopting functional programming paradigms. This is because functional programming can help make it easier to write code that is concise, modular, and reusable, which can be useful when working on large machine learning projects."><meta name=keywords content="Functorch,JAX,ChatGPT,OpenAI"><meta itemprop=name content="Functional Frameworks in Machine Learning"><meta itemprop=description content="This is my conversation with OpenAI&rsquo;s ChatGPT. I want to clarify I have no intention of using this technology for monotization. I&rsquo;ve used it for generating knowledge and nothing else.
Functional Frameworks Are a Thing Q: I&rsquo;ve been noticing machine learning frameworks such as JAX and functorch have been adopting functional programming paradigms. Is this true?
Yes, it&rsquo;s true that some machine learning frameworks are adopting functional programming paradigms. This is because functional programming can help make it easier to write code that is concise, modular, and reusable, which can be useful when working on large machine learning projects."><meta itemprop=datePublished content="2022-12-02T10:50:57+08:00"><meta itemprop=dateModified content="2022-12-02T10:50:57+08:00"><meta itemprop=wordCount content="1500"><meta itemprop=keywords content="Functorch,JAX,ChatGPT,OpenAI,"><meta property="og:title" content="Functional Frameworks in Machine Learning"><meta property="og:description" content="This is my conversation with OpenAI&rsquo;s ChatGPT. I want to clarify I have no intention of using this technology for monotization. I&rsquo;ve used it for generating knowledge and nothing else.
Functional Frameworks Are a Thing Q: I&rsquo;ve been noticing machine learning frameworks such as JAX and functorch have been adopting functional programming paradigms. Is this true?
Yes, it&rsquo;s true that some machine learning frameworks are adopting functional programming paradigms. This is because functional programming can help make it easier to write code that is concise, modular, and reusable, which can be useful when working on large machine learning projects."><meta property="og:type" content="article"><meta property="og:url" content="/posts/2022-12-02-functional-programming-in-ml/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2022-12-02T10:50:57+08:00"><meta property="article:modified_time" content="2022-12-02T10:50:57+08:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Functional Frameworks in Machine Learning"><meta name=twitter:description content="This is my conversation with OpenAI&rsquo;s ChatGPT. I want to clarify I have no intention of using this technology for monotization. I&rsquo;ve used it for generating knowledge and nothing else.
Functional Frameworks Are a Thing Q: I&rsquo;ve been noticing machine learning frameworks such as JAX and functorch have been adopting functional programming paradigms. Is this true?
Yes, it&rsquo;s true that some machine learning frameworks are adopting functional programming paradigms. This is because functional programming can help make it easier to write code that is concise, modular, and reusable, which can be useful when working on large machine learning projects."><meta name=application-name content="FixIt"><meta name=apple-mobile-web-app-title content="FixIt"><meta name=theme-color data-light=#f8f8f8 data-dark=#252627 content="#f8f8f8"><meta name=msapplication-TileColor content="#da532c"><link rel="shortcut icon" type=image/x-icon href=/favicon.ico><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=mask-icon href=/safari-pinned-tab.svg color=#5bbad5><link rel=canonical href=/posts/2022-12-02-functional-programming-in-ml/><link rel=prev href=/posts/2022-11-17-information-proc-org-rec/><link rel=next href=/posts/2023-02-01-mlaas-vs-mlops/><link rel=stylesheet href=/css/style.min.css><link rel=stylesheet href=/lib/fontawesome-free/all.min.css><link rel=stylesheet href=/lib/animate/animate.min.css><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","headline":"Functional Frameworks in Machine Learning","inLanguage":"en","mainEntityOfPage":{"@type":"WebPage","@id":"\/posts\/2022-12-02-functional-programming-in-ml\/"},"genre":"posts","keywords":"Functorch, JAX, ChatGPT, OpenAI","wordcount":1500,"url":"\/posts\/2022-12-02-functional-programming-in-ml\/","datePublished":"2022-12-02T10:50:57+08:00","dateModified":"2022-12-02T10:50:57+08:00","publisher":{"@type":"Organization","name":""},"author":{"@type":"Person","name":"Author"},"description":""}</script></head><body data-header-desktop=sticky data-header-mobile=auto><script>(window.localStorage?.getItem("theme")?localStorage.getItem("theme")==="dark":"auto"==="auto"?window.matchMedia("(prefers-color-scheme: dark)").matches:"auto"==="dark")&&document.body.setAttribute("data-theme","dark")</script><div class=wrapper data-page-style=normal><header class="desktop animate__faster" id=header-desktop><div class=header-wrapper><div class=header-title><a href=/ title><img loading=lazy src=/fixit.min.svg srcset="/fixit.min.svg, /fixit.min.svg 1.5x, /fixit.min.svg 2x" sizes=auto data-title=/fixit.min.svg data-alt=/fixit.min.svg class=logo style="background:url(/svg/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e)'><span class=header-title-text>My Hugo FixIt Site</span></a><span class=header-subtitle></span></div><nav><ul class=menu><li class=menu-item><a class=menu-link href=/posts/><i class="fa-solid fa-archive fa-fw fa-sm" aria-hidden=true></i> Posts</a></li><li class=menu-item><a class=menu-link href=/categories/><i class="fa-solid fa-th fa-fw fa-sm" aria-hidden=true></i> Categories</a></li><li class=menu-item><a class=menu-link href=/tags/><i class="fa-solid fa-tags fa-fw fa-sm" aria-hidden=true></i> Tags</a></li><li class="menu-item delimiter"></li><li class="menu-item theme-switch" title="Switch Theme"><i class="fa-solid fa-adjust fa-fw" aria-hidden=true></i></li></ul></nav></div></header><header class="mobile animate__faster" id=header-mobile><div class=header-container><div class=header-wrapper><div class=header-title><a href=/ title><img loading=lazy src=/fixit.min.svg srcset="/fixit.min.svg, /fixit.min.svg 1.5x, /fixit.min.svg 2x" sizes=auto data-title=/fixit.min.svg data-alt=/fixit.min.svg class=logo style="background:url(/svg/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e)'><span class=header-title-text>My Hugo FixIt Site</span></a><span class=header-subtitle></span></div><div class=menu-toggle id=menu-toggle-mobile><span></span><span></span><span></span></div></div><nav><ul class=menu id=menu-mobile><li class=menu-item><a class=menu-link href=/posts/><i class="fa-solid fa-archive fa-fw fa-sm" aria-hidden=true></i> Posts</a></li><li class=menu-item><a class=menu-link href=/categories/><i class="fa-solid fa-th fa-fw fa-sm" aria-hidden=true></i> Categories</a></li><li class=menu-item><a class=menu-link href=/tags/><i class="fa-solid fa-tags fa-fw fa-sm" aria-hidden=true></i> Tags</a></li><li class="menu-item menu-system"><span class="menu-system-item theme-switch" title="Switch Theme"><i class="fa-solid fa-adjust fa-fw" aria-hidden=true></i></span></li></ul></nav></div></header><main class=container><aside class=toc id=toc-auto><h2 class=toc-title>Contents&nbsp;<i class="toc-icon fa-solid fa-angle-down fa-fw" aria-hidden=true></i></h2><div class=toc-content id=toc-content-auto></div></aside><aside class=aside-custom></aside><article class="page single"><div class=header><h1 class="single-title animate__animated animate__flipInX"><span>Functional Frameworks in Machine Learning</span></h1></div><div class=post-meta><div class=post-meta-line><span class=post-author><span class=author><i class="fa-solid fa-user-circle" aria-hidden=true></i>
Anonymous</span></span>
<span class=post-category>included in <a href=/categories/machine-learning/><i class="fa-regular fa-folder fa-fw" aria-hidden=true></i> Machine Learning</a></span></div><div class=post-meta-line><span title="published on 2022-12-02 10:50:57"><i class="fa-regular fa-calendar-alt fa-fw me-1" aria-hidden=true></i><time datetime=2022-12-02>2022-12-02</time></span>&nbsp;<span title="Updated on 2022-12-02 10:50:57"><i class="fa-regular fa-edit fa-fw me-1" aria-hidden=true></i><time datetime=2022-12-02>2022-12-02</time></span>&nbsp;<span><i class="fa-solid fa-pencil-alt fa-fw me-1" aria-hidden=true></i>1500 words</span>&nbsp;<span><i class="fa-regular fa-clock fa-fw me-1" aria-hidden=true></i>8 minutes</span>&nbsp;</div></div><div class="details toc" id=toc-static data-kept=false><div class="details-summary toc-title"><span>Contents</span>
<span><i class="details-icon fa-solid fa-angle-right" aria-hidden=true></i></span></div><div class="details-content toc-content" id=toc-content-static><nav id=TableOfContents><ul><li><a href=#functional-frameworks-are-a-thing>Functional Frameworks Are a Thing</a></li><li><a href=#what-are-per-sample-gradients>What Are Per Sample Gradients?</a></li><li><a href=#why-would-i-want-to-use-these-frameworks>Why Would I Want to Use These Frameworks?</a></li><li><a href=#can-you-give-me-an-example>Can You Give Me an Example?</a></li><li><a href=#a-more-complicated-example>A More Complicated Example</a></li><li><a href=#making-my-conversation-into-a-blog-post>Making My Conversation into a Blog Post?</a></li></ul></nav></div></div><div class=content id=content><p><strong>This is my conversation with OpenAI&rsquo;s ChatGPT</strong>. I want to clarify I have no intention of using this technology for monotization. I&rsquo;ve used it for generating knowledge and nothing else.</p><h2 id=functional-frameworks-are-a-thing>Functional Frameworks Are a Thing</h2><blockquote><p>Q: I&rsquo;ve been noticing machine learning frameworks such as JAX and functorch have been adopting functional programming paradigms. Is this true?</p></blockquote><p>Yes, it&rsquo;s true that some machine learning frameworks are adopting functional programming paradigms. This is because functional programming can help make it easier to write code that is concise, modular, and reusable, which can be useful when working on large machine learning projects. Additionally, functional programming can help make it easier to parallelize code and perform automatic differentiation, which are important capabilities for many machine learning tasks.</p><p>JAX, for example, is a functional programming framework for machine learning that is built on top of the popular NumPy library. It allows users to write code using functions and automatic differentiation, and it can run on GPUs and other hardware accelerators.</p><p>Functorch is another example of a machine learning framework that uses functional programming. It is built on top of the popular PyTorch library and allows users to write code using functional programming constructs.</p><p>Overall, the use of functional programming in machine learning is still relatively new, but it is gaining traction as a way to improve the efficiency and modularity of machine learning code.</p><h2 id=what-are-per-sample-gradients>What Are Per Sample Gradients?</h2><blockquote><p>Q: What is per sample gradients and why do these frameworks help with the computation of per sample gradients?</p></blockquote><p>Per-sample gradients are gradients that are calculated for each individual sample in a dataset, rather than for the entire dataset as a whole. This can be useful for tasks such as learning with very large datasets, where it may not be possible to calculate gradients for the entire dataset at once.</p><p>Some machine learning frameworks, such as JAX and Functorch, are designed to make it easier to calculate per-sample gradients. These frameworks typically use functional programming constructs, such as higher-order functions and automatic differentiation, to allow users to write code that can calculate gradients for individual samples in a concise and modular way.</p><p>For example, in JAX, users can write a function that calculates the gradient of a model&rsquo;s output with respect to its inputs, and then use this function to calculate the gradient for each sample in a dataset. This can be done in a parallelized and efficient manner, which can make it much easier to work with large datasets.</p><p>In general, the ability to calculate per-sample gradients can be important for many machine learning tasks, and frameworks like JAX and Functorch can make it easier to do so.</p><h2 id=why-would-i-want-to-use-these-frameworks>Why Would I Want to Use These Frameworks?</h2><blockquote><p>Q: For a person who is using Pytorch for training models, would they benefit in switching to Functorch?</p></blockquote><p>Whether a person who is using PyTorch for training models would benefit from switching to Functorch would depend on a number of factors, including their specific goals and the specific features of the two frameworks.</p><p>Functorch is a functional programming framework built on top of PyTorch, so it offers many of the same capabilities as PyTorch, such as support for deep learning and neural networks. However, Functorch also adds functional programming constructs, such as higher-order functions and automatic differentiation, which can make it easier to write concise, modular, and reusable code.</p><p>If a person is already familiar with PyTorch and is happy with the features and capabilities it offers, then switching to Functorch may not necessarily provide any significant benefits. However, if a person is looking for a way to improve the efficiency and modularity of their machine learning code, or if they are interested in using functional programming techniques in their work, then Functorch might be a good option to consider.</p><p>Ultimately, whether a person would benefit from switching from PyTorch to Functorch would depend on their specific needs and goals. It might be worth exploring both frameworks to see which one works best for a particular project or use case.</p><h2 id=can-you-give-me-an-example>Can You Give Me an Example?</h2><p>Here is an example of a simple machine learning model written in vanilla PyTorch:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> torch  
</span></span><span style=display:flex><span><span style=color:#75715e># Define a model with a single linear layer </span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>LinearModel</span>(torch<span style=color:#f92672>.</span>nn<span style=color:#f92672>.</span>Module):     
</span></span><span style=display:flex><span>	<span style=color:#66d9ef>def</span> __init__(self, input_size, output_size):         
</span></span><span style=display:flex><span>		super()<span style=color:#f92672>.</span>__init__()         
</span></span><span style=display:flex><span>		self<span style=color:#f92672>.</span>linear <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>nn<span style=color:#f92672>.</span>Linear(input_size, output_size)          
</span></span><span style=display:flex><span>	<span style=color:#66d9ef>def</span> <span style=color:#a6e22e>forward</span>(self, x):         
</span></span><span style=display:flex><span>		<span style=color:#66d9ef>return</span> self<span style=color:#f92672>.</span>linear(x)  
</span></span><span style=display:flex><span><span style=color:#75715e># Create an instance of the model </span>
</span></span><span style=display:flex><span>model <span style=color:#f92672>=</span> LinearModel(<span style=color:#ae81ff>10</span>, <span style=color:#ae81ff>1</span>)  
</span></span><span style=display:flex><span><span style=color:#75715e># Generate some random input data </span>
</span></span><span style=display:flex><span>x <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>randn(<span style=color:#ae81ff>100</span>, <span style=color:#ae81ff>10</span>)  
</span></span><span style=display:flex><span><span style=color:#75715e># Use the model to make predictions on the input data </span>
</span></span><span style=display:flex><span>y_pred <span style=color:#f92672>=</span> model(x)  
</span></span><span style=display:flex><span><span style=color:#75715e># Calculate the loss </span>
</span></span><span style=display:flex><span>loss <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>nn<span style=color:#f92672>.</span>functional<span style=color:#f92672>.</span>mse_loss(y_pred, y)  
</span></span><span style=display:flex><span><span style=color:#75715e># Backpropagate the loss to calculate the gradients </span>
</span></span><span style=display:flex><span>loss<span style=color:#f92672>.</span>backward()  
</span></span><span style=display:flex><span><span style=color:#75715e># Update the model parameters </span>
</span></span><span style=display:flex><span>optimizer <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>optim<span style=color:#f92672>.</span>SGD(model<span style=color:#f92672>.</span>parameters(), lr<span style=color:#f92672>=</span><span style=color:#ae81ff>0.01</span>) 
</span></span><span style=display:flex><span>optimizer<span style=color:#f92672>.</span>step()
</span></span></code></pre></div><p>Here is the same model written using Functorch:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> functorch <span style=color:#66d9ef>as</span> fc  
</span></span><span style=display:flex><span><span style=color:#75715e># Define a model with a single linear layer using Functorch&#39;s functional API</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>linear_model</span>(input_size, output_size):     
</span></span><span style=display:flex><span>	<span style=color:#66d9ef>def</span> <span style=color:#a6e22e>forward</span>(x):         
</span></span><span style=display:flex><span>		linear <span style=color:#f92672>=</span> fc<span style=color:#f92672>.</span>Linear(input_size, output_size)         
</span></span><span style=display:flex><span>		<span style=color:#66d9ef>return</span> linear(x)     
</span></span><span style=display:flex><span>	<span style=color:#66d9ef>return</span> fc<span style=color:#f92672>.</span>Model(forward)  
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Create an instance of the model</span>
</span></span><span style=display:flex><span>model <span style=color:#f92672>=</span> linear_model(<span style=color:#ae81ff>10</span>, <span style=color:#ae81ff>1</span>)  
</span></span><span style=display:flex><span><span style=color:#75715e># Generate some random input data </span>
</span></span><span style=display:flex><span>x <span style=color:#f92672>=</span> fc<span style=color:#f92672>.</span>randn(<span style=color:#ae81ff>100</span>, <span style=color:#ae81ff>10</span>)  
</span></span><span style=display:flex><span><span style=color:#75715e># Use the model to make predictions on the input data </span>
</span></span><span style=display:flex><span>y_pred <span style=color:#f92672>=</span> model(x)  
</span></span><span style=display:flex><span><span style=color:#75715e># Calculate the loss </span>
</span></span><span style=display:flex><span>loss <span style=color:#f92672>=</span> fc<span style=color:#f92672>.</span>mse_loss(y_pred, y)  
</span></span><span style=display:flex><span><span style=color:#75715e># Backpropagate the loss to calculate the gradients </span>
</span></span><span style=display:flex><span>loss<span style=color:#f92672>.</span>backward()  
</span></span><span style=display:flex><span><span style=color:#75715e># Update the model parameters </span>
</span></span><span style=display:flex><span>optimizer <span style=color:#f92672>=</span> fc<span style=color:#f92672>.</span>SGD(model<span style=color:#f92672>.</span>parameters(), lr<span style=color:#f92672>=</span><span style=color:#ae81ff>0.01</span>) 
</span></span><span style=display:flex><span>optimizer<span style=color:#f92672>.</span>step()
</span></span></code></pre></div><p>In this example, the model is defined using Functorch&rsquo;s functional API, which allows us to write the model as a function that takes inputs and returns outputs. This can make the code more concise and easier to read than the PyTorch version, which uses object-oriented programming. Additionally, Functorch automatically calculates gradients and performs backpropagation when <code>loss.backward()</code> is called, which can make the code even simpler and more modular.</p><h2 id=a-more-complicated-example>A More Complicated Example</h2><p>Sure, here is a more complicated example of a machine learning model written using Functorch:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> functorch <span style=color:#66d9ef>as</span> fc  
</span></span><span style=display:flex><span><span style=color:#75715e># Define a convolutional neural network using Functorch&#39;s functional API </span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>convnet</span>(input_size, num_classes):     
</span></span><span style=display:flex><span>	<span style=color:#66d9ef>def</span> <span style=color:#a6e22e>forward</span>(x):         
</span></span><span style=display:flex><span>		<span style=color:#75715e># Apply a sequence of convolutional and pooling layers         </span>
</span></span><span style=display:flex><span>		x <span style=color:#f92672>=</span> fc<span style=color:#f92672>.</span>Conv2d(x, <span style=color:#ae81ff>32</span>, kernel_size<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span>, padding<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>)         
</span></span><span style=display:flex><span>		x <span style=color:#f92672>=</span> fc<span style=color:#f92672>.</span>ReLU(x)         
</span></span><span style=display:flex><span>		x <span style=color:#f92672>=</span> fc<span style=color:#f92672>.</span>MaxPool2d(x, kernel_size<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>)         
</span></span><span style=display:flex><span>		x <span style=color:#f92672>=</span> fc<span style=color:#f92672>.</span>Conv2d(x, <span style=color:#ae81ff>64</span>, kernel_size<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span>, padding<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>)         
</span></span><span style=display:flex><span>		x <span style=color:#f92672>=</span> fc<span style=color:#f92672>.</span>ReLU(x)         
</span></span><span style=display:flex><span>		x <span style=color:#f92672>=</span> fc<span style=color:#f92672>.</span>MaxPool2d(x, kernel_size<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>)          
</span></span><span style=display:flex><span>		<span style=color:#75715e># Flatten the output of the convolutional layers         </span>
</span></span><span style=display:flex><span>		x <span style=color:#f92672>=</span> x<span style=color:#f92672>.</span>view(x<span style=color:#f92672>.</span>size(<span style=color:#ae81ff>0</span>), <span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>)          
</span></span><span style=display:flex><span>		<span style=color:#75715e># Apply a sequence of fully-connected layers         </span>
</span></span><span style=display:flex><span>		x <span style=color:#f92672>=</span> fc<span style=color:#f92672>.</span>Linear(x, <span style=color:#ae81ff>512</span>)         
</span></span><span style=display:flex><span>		x <span style=color:#f92672>=</span> fc<span style=color:#f92672>.</span>ReLU(x)         
</span></span><span style=display:flex><span>		x <span style=color:#f92672>=</span> fc<span style=color:#f92672>.</span>Linear(x, num_classes)          
</span></span><span style=display:flex><span>		<span style=color:#75715e># Return the logits         </span>
</span></span><span style=display:flex><span>		<span style=color:#66d9ef>return</span> x      
</span></span><span style=display:flex><span>	<span style=color:#66d9ef>return</span> fc<span style=color:#f92672>.</span>Model(forward)  
</span></span><span style=display:flex><span><span style=color:#75715e># Create an instance of the model </span>
</span></span><span style=display:flex><span>model <span style=color:#f92672>=</span> convnet(input_size<span style=color:#f92672>=</span>(<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>32</span>, <span style=color:#ae81ff>32</span>), num_classes<span style=color:#f92672>=</span><span style=color:#ae81ff>10</span>)  
</span></span><span style=display:flex><span><span style=color:#75715e># Generate some random input data </span>
</span></span><span style=display:flex><span>x <span style=color:#f92672>=</span> fc<span style=color:#f92672>.</span>randn(<span style=color:#ae81ff>100</span>, <span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>32</span>, <span style=color:#ae81ff>32</span>)  
</span></span><span style=display:flex><span><span style=color:#75715e># Use the model to make predictions on the input data </span>
</span></span><span style=display:flex><span>y_pred <span style=color:#f92672>=</span> model(x)  
</span></span><span style=display:flex><span><span style=color:#75715e># Calculate the loss </span>
</span></span><span style=display:flex><span>loss <span style=color:#f92672>=</span> fc<span style=color:#f92672>.</span>cross_entropy_loss(y_pred, y)  
</span></span><span style=display:flex><span><span style=color:#75715e># Backpropagate the loss to calculate the gradients </span>
</span></span><span style=display:flex><span>loss<span style=color:#f92672>.</span>backward()  
</span></span><span style=display:flex><span><span style=color:#75715e># Update the model parameters </span>
</span></span><span style=display:flex><span>optimizer <span style=color:#f92672>=</span> fc<span style=color:#f92672>.</span>SGD(model<span style=color:#f92672>.</span>parameters(), lr<span style=color:#f92672>=</span><span style=color:#ae81ff>0.01</span>) optimizer<span style=color:#f92672>.</span>step()
</span></span></code></pre></div><p>In this example, we define a convolutional neural network using Functorch&rsquo;s functional API. This allows us to write the model as a function that takes inputs and returns outputs, and it allows us to use functional programming constructs such as higher-order functions and automatic differentiation. This can make the code more concise and easier to read than if we were to define the model using object-oriented programming, as we would have to do in PyTorch.</p><p>Additionally, Functorch automatically calculates gradients and performs backpropagation when <code>loss.backward()</code> is called, which can make the code even simpler and more modular. This can be particularly useful when working with complex neural network architectures, as it can help reduce the amount of boilerplate code that needs to be written.</p><h2 id=making-my-conversation-into-a-blog-post>Making My Conversation into a Blog Post?</h2><blockquote><p>Q: How would our conversation until here look like as a blog post?</p></blockquote><p>Here is an example of how our conversation until now could be written as a blog post:</p><p><strong>Title: Functional Programming in Machine Learning: An Introduction to Functorch and JAX</strong></p><p>Functional programming is a programming paradigm that focuses on the use of functions to model computations and data. In recent years, functional programming has been gaining popularity in the machine learning community, with some frameworks, such as Functorch and JAX, adopting functional programming paradigms.</p><p>Functorch is a functional programming framework built on top of PyTorch, a popular deep learning library. It allows users to write code using functional programming constructs, such as higher-order functions and automatic differentiation, which can make it easier to write concise, modular, and reusable code.</p><p>JAX is another functional programming framework for machine learning, built on top of the NumPy library. Like Functorch, it allows users to write code using functional programming constructs and to perform automatic differentiation. Additionally, JAX can run on GPUs and other hardware accelerators, which can make it easier to scale up machine learning code and work with large datasets.</p><p>The use of functional programming in machine learning is still relatively new, but it is gaining traction as a way to improve the efficiency and modularity of machine learning code. If you are interested in functional programming and machine learning, then learning about Functorch and JAX could be a useful addition to your skillset.</p></div><div class=post-footer id=post-footer><div class=post-info><div class=post-info-line><div class=post-info-mod><span title="Updated on 2022-12-02 10:50:57">Updated on 2022-12-02&nbsp;</span></div><div class=post-info-license><span><a rel="license external nofollow noopener noreferrer" href=https://creativecommons.org/licenses/by-nc/4.0/ target=_blank>CC BY-NC 4.0</a></span></div></div><div class=post-info-line><div class=post-info-md></div><div class=post-info-share><span><a href=javascript:void(0); title="Share on Twitter" data-sharer=twitter data-url=/posts/2022-12-02-functional-programming-in-ml/ data-title="Functional Frameworks in Machine Learning" data-hashtags=Functorch,JAX,ChatGPT,OpenAI><i class="fa-brands fa-twitter fa-fw" aria-hidden=true></i></a>
<a href=javascript:void(0); title="Share on Facebook" data-sharer=facebook data-url=/posts/2022-12-02-functional-programming-in-ml/ data-hashtag=Functorch><i class="fa-brands fa-facebook-square fa-fw" aria-hidden=true></i></a>
<a href=javascript:void(0); title="Share on 微博" data-sharer=weibo data-url=/posts/2022-12-02-functional-programming-in-ml/ data-title="Functional Frameworks in Machine Learning"><i class="fa-brands fa-weibo fa-fw" aria-hidden=true></i></a></span></div></div></div><div class=post-info-more><section class=post-tags><i class="fa-solid fa-tags fa-fw me-1" aria-hidden=true></i><a href=/tags/functorch/ class=post-tag>Functorch</a><a href=/tags/jax/ class=post-tag>JAX</a><a href=/tags/chatgpt/ class=post-tag>ChatGPT</a><a href=/tags/openai/ class=post-tag>OpenAI</a></section><section><span><a href=javascript:void(0); onclick=window.history.back()>Back</a></span>&nbsp;|&nbsp;<span><a href=/>Home</a></span></section></div><div class=post-nav><a href=/posts/2022-11-17-information-proc-org-rec/ class=post-nav-item rel=prev title="Information- Processing, Organization and Retrieval"><i class="fa-solid fa-angle-left fa-fw" aria-hidden=true></i>Information- Processing, Organization and Retrieval</a>
<a href=/posts/2023-02-01-mlaas-vs-mlops/ class=post-nav-item rel=next title="MLaaS vs MLOps">MLaaS vs MLOps<i class="fa-solid fa-angle-right fa-fw" aria-hidden=true></i></a></div></div></article></main><footer class=footer><div class=footer-container><div class="footer-line powered">Powered by <a href=https://gohugo.io/ target=_blank rel="external nofollow noopener noreferrer" title="Hugo 0.116.0">Hugo</a> | Theme - <a href=https://github.com/hugo-fixit/FixIt target=_blank rel=external title="FixIt v0.2.18"><img class=fixit-icon src=/fixit.min.svg alt="FixIt logo">&nbsp;FixIt</a></div><div class="footer-line copyright" itemscope itemtype=http://schema.org/CreativeWork><i class="fa-regular fa-copyright fa-fw" aria-hidden=true></i>
<span itemprop=copyrightYear>2023</span><span class=author itemprop=copyrightHolder>
<a href=/></a></span></div><div class="footer-line statistics"></div></div></footer></div><div class=widgets><div class="fixed-buttons animate__faster d-none"><div class="fixed-button back-to-top" role=button aria-label="Back to Top"><i class="fa-solid fa-arrow-up fa-fw" aria-hidden=true></i><span class="variant-numeric d-none">0%</span></div></div><div id=mask></div><noscript><div class=noscript-warning>Theme FixIt works best with JavaScript enabled.</div></noscript></div><link rel=stylesheet href=/lib/katex/katex.min.css><link rel=stylesheet href=/lib/cookieconsent/cookieconsent.min.css><script src=/lib/sharer/sharer.min.js async defer></script><script src=/lib/katex/katex.min.js defer></script><script src=/lib/katex/auto-render.min.js defer></script><script src=/lib/katex/copy-tex.min.js defer></script><script src=/lib/katex/mhchem.min.js defer></script><script src=/lib/cookieconsent/cookieconsent.min.js defer></script><script>window.config={code:{copyTitle:"Copy to clipboard",editLockTitle:"Lock editable code block",editUnLockTitle:"Unlock editable code block",editable:!0,maxShownLines:10},comment:{enable:!1},cookieconsent:{content:{dismiss:"Got it!",link:"Learn more",message:"This website uses Cookies to improve your experience."},enable:!0,palette:{button:{background:"#f0f0f0"},popup:{background:"#1aa3ff"}},theme:"edgeless"},math:{delimiters:[{display:!0,left:"$$",right:"$$"},{display:!0,left:"\\[",right:"\\]"},{display:!0,left:"\\begin{equation}",right:"\\end{equation}"},{display:!0,left:"\\begin{equation*}",right:"\\end{equation*}"},{display:!0,left:"\\begin{align}",right:"\\end{align}"},{display:!0,left:"\\begin{align*}",right:"\\end{align*}"},{display:!0,left:"\\begin{alignat}",right:"\\end{alignat}"},{display:!0,left:"\\begin{alignat*}",right:"\\end{alignat*}"},{display:!0,left:"\\begin{gather}",right:"\\end{gather}"},{display:!0,left:"\\begin{CD}",right:"\\end{CD}"},{display:!1,left:"$",right:"$"},{display:!1,left:"\\(",right:"\\)"}],strict:!1}}</script><script src=/js/theme.min.js defer></script></body></html>