<!doctype html><html lang=en dir=ltr class=scroll-smooth data-default-appearance=light data-auto-appearance=true><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=theme-color content="rgb(255,255,255)"><title>Functional Frameworks in Machine Learning &#183; The Pragmatic Mentor</title>
<meta name=title content="Functional Frameworks in Machine Learning &#183; The Pragmatic Mentor"><script type=text/javascript src=/js/appearance.min.74ad8406faea02f3e186ba5126249aaeed9073629e04b05037b903396b188724.js integrity="sha256-dK2EBvrqAvPhhrpRJiSaru2Qc2KeBLBQN7kDOWsYhyQ="></script><link type=text/css rel=stylesheet href=/css/main.bundle.min.9602fe0216290b9ff0322c1fd14e88ab9fc0a13741f4de563f67831708d72bb2.css integrity="sha256-lgL+AhYpC5/wMiwf0U6Iq5/AoTdB9N5WP2eDFwjXK7I="><meta name=description content="
      
        This is my conversation with OpenAI&rsquo;s ChatGPT. I want to clarify I have no intention of using this technology for monotization. I&rsquo;ve used it for generating knowledge and nothing else.
Functional Frameworks Are a Thing # Q: I&rsquo;ve been noticing machine learning frameworks such as JAX and functorch have been adopting functional programming paradigms. Is this true?
Yes, it&rsquo;s true that some machine learning frameworks are adopting functional programming paradigms. This is because functional programming can help make it easier to write code that is concise, modular, and reusable, which can be useful when working on large machine learning projects.
      
    "><link rel=canonical href=https://www.pragmatic-mentor.xyz/posts/2022-12-02-functional-programming-in-ml/><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=manifest href=/site.webmanifest><meta property="og:url" content="https://www.pragmatic-mentor.xyz/posts/2022-12-02-functional-programming-in-ml/"><meta property="og:site_name" content="The Pragmatic Mentor"><meta property="og:title" content="Functional Frameworks in Machine Learning"><meta property="og:description" content="This is my conversation with OpenAI’s ChatGPT. I want to clarify I have no intention of using this technology for monotization. I’ve used it for generating knowledge and nothing else.
Functional Frameworks Are a Thing # Q: I’ve been noticing machine learning frameworks such as JAX and functorch have been adopting functional programming paradigms. Is this true?
Yes, it’s true that some machine learning frameworks are adopting functional programming paradigms. This is because functional programming can help make it easier to write code that is concise, modular, and reusable, which can be useful when working on large machine learning projects."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2022-12-02T10:50:57+08:00"><meta property="article:modified_time" content="2022-12-02T10:50:57+08:00"><meta property="article:tag" content="Functorch"><meta property="article:tag" content="JAX"><meta property="article:tag" content="ChatGPT"><meta property="article:tag" content="OpenAI"><meta name=twitter:card content="summary"><meta name=twitter:title content="Functional Frameworks in Machine Learning"><meta name=twitter:description content="This is my conversation with OpenAI’s ChatGPT. I want to clarify I have no intention of using this technology for monotization. I’ve used it for generating knowledge and nothing else.
Functional Frameworks Are a Thing # Q: I’ve been noticing machine learning frameworks such as JAX and functorch have been adopting functional programming paradigms. Is this true?
Yes, it’s true that some machine learning frameworks are adopting functional programming paradigms. This is because functional programming can help make it easier to write code that is concise, modular, and reusable, which can be useful when working on large machine learning projects."><script type=application/ld+json>{"@context":"https://schema.org","@type":"Article","articleSection":"Posts","name":"Functional Frameworks in Machine Learning","headline":"Functional Frameworks in Machine Learning","abstract":"This is my conversation with OpenAI\u0026rsquo;s ChatGPT. I want to clarify I have no intention of using this technology for monotization. I\u0026rsquo;ve used it for generating knowledge and nothing else.\nFunctional Frameworks Are a Thing # Q: I\u0026rsquo;ve been noticing machine learning frameworks such as JAX and functorch have been adopting functional programming paradigms. Is this true?\nYes, it\u0026rsquo;s true that some machine learning frameworks are adopting functional programming paradigms. This is because functional programming can help make it easier to write code that is concise, modular, and reusable, which can be useful when working on large machine learning projects.","inLanguage":"en","url":"https:\/\/www.pragmatic-mentor.xyz\/posts\/2022-12-02-functional-programming-in-ml\/","author":{"@type":"Person","name":""},"copyrightYear":"2022","dateCreated":"2022-12-02T10:50:57\u002b08:00","datePublished":"2022-12-02T10:50:57\u002b08:00","dateModified":"2022-12-02T10:50:57\u002b08:00","keywords":["Functorch","JAX","ChatGPT","OpenAI"],"mainEntityOfPage":"true","wordCount":"1504"}</script></head><body class="m-auto flex h-screen max-w-7xl flex-col bg-neutral px-6 text-lg leading-7 text-neutral-900 sm:px-14 md:px-24 lg:px-32 dark:bg-neutral-800 dark:text-neutral"><div id=the-top class="absolute flex self-center"><a class="-translate-y-8 rounded-b-lg bg-primary-200 px-3 py-1 text-sm focus:translate-y-0 dark:bg-neutral-600" href=#main-content><span class="pe-2 font-bold text-primary-600 dark:text-primary-400">&darr;</span>Skip to main content</a></div><header class="py-6 font-semibold text-neutral-900 print:hidden sm:py-10 dark:text-neutral"><nav class="flex items-start justify-between sm:items-center"><div class="flex flex-row items-center"><a class="decoration-primary-500 hover:underline hover:decoration-2 hover:underline-offset-2" rel=me href=/>The Pragmatic Mentor</a></div><ul class="flex list-none flex-col text-end sm:flex-row"><li class="group mb-1 sm:mb-0 sm:me-7 sm:last:me-0.5"><a href=/posts/ title><span class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2">Blog</span></a></li><li class="group mb-1 sm:mb-0 sm:me-7 sm:last:me-0.5"><a href=/about/ title><span class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2">About</span></a></li><li class="group mb-1 sm:mb-0 sm:me-7 sm:last:me-0.5"><a href=/favorites/ title><span class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2">Favorites</span></a></li><li class="group mb-1 sm:mb-0 sm:me-7 sm:last:me-0.5"><a href=/tags/ title><span class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2">Tags</span></a></li></ul></nav></header><div class="relative flex grow flex-col"><main id=main-content class=grow><article><header class=max-w-prose><h1 class="mt-0 text-4xl font-extrabold text-neutral-900 dark:text-neutral">Functional Frameworks in Machine Learning</h1><div class="mb-12 mt-8 text-base text-neutral-500 print:hidden dark:text-neutral-400"><div class="flex flex-row flex-wrap items-center"><time datetime="2022-12-02 10:50:57 +0800 +0800">2 December 2022</time><span class="px-2 text-primary-500">&#183;</span><span title="Reading time">8 mins</span></div></div></header><section class="prose mt-0 flex max-w-full flex-col dark:prose-invert lg:flex-row"><div class="min-h-0 min-w-0 max-w-prose grow"><p><strong>This is my conversation with OpenAI&rsquo;s ChatGPT</strong>. I want to clarify I have no intention of using this technology for monotization. I&rsquo;ve used it for generating knowledge and nothing else.</p><h2 id=functional-frameworks-are-a-thing class="relative group">Functional Frameworks Are a Thing <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#functional-frameworks-are-a-thing aria-label=Anchor>#</a></span></h2><blockquote><p>Q: I&rsquo;ve been noticing machine learning frameworks such as JAX and functorch have been adopting functional programming paradigms. Is this true?</p></blockquote><p>Yes, it&rsquo;s true that some machine learning frameworks are adopting functional programming paradigms. This is because functional programming can help make it easier to write code that is concise, modular, and reusable, which can be useful when working on large machine learning projects. Additionally, functional programming can help make it easier to parallelize code and perform automatic differentiation, which are important capabilities for many machine learning tasks.</p><p>JAX, for example, is a functional programming framework for machine learning that is built on top of the popular NumPy library. It allows users to write code using functions and automatic differentiation, and it can run on GPUs and other hardware accelerators.</p><p>Functorch is another example of a machine learning framework that uses functional programming. It is built on top of the popular PyTorch library and allows users to write code using functional programming constructs.</p><p>Overall, the use of functional programming in machine learning is still relatively new, but it is gaining traction as a way to improve the efficiency and modularity of machine learning code.</p><h2 id=what-are-per-sample-gradients class="relative group">What Are Per Sample Gradients? <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#what-are-per-sample-gradients aria-label=Anchor>#</a></span></h2><blockquote><p>Q: What is per sample gradients and why do these frameworks help with the computation of per sample gradients?</p></blockquote><p>Per-sample gradients are gradients that are calculated for each individual sample in a dataset, rather than for the entire dataset as a whole. This can be useful for tasks such as learning with very large datasets, where it may not be possible to calculate gradients for the entire dataset at once.</p><p>Some machine learning frameworks, such as JAX and Functorch, are designed to make it easier to calculate per-sample gradients. These frameworks typically use functional programming constructs, such as higher-order functions and automatic differentiation, to allow users to write code that can calculate gradients for individual samples in a concise and modular way.</p><p>For example, in JAX, users can write a function that calculates the gradient of a model&rsquo;s output with respect to its inputs, and then use this function to calculate the gradient for each sample in a dataset. This can be done in a parallelized and efficient manner, which can make it much easier to work with large datasets.</p><p>In general, the ability to calculate per-sample gradients can be important for many machine learning tasks, and frameworks like JAX and Functorch can make it easier to do so.</p><h2 id=why-would-i-want-to-use-these-frameworks class="relative group">Why Would I Want to Use These Frameworks? <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#why-would-i-want-to-use-these-frameworks aria-label=Anchor>#</a></span></h2><blockquote><p>Q: For a person who is using Pytorch for training models, would they benefit in switching to Functorch?</p></blockquote><p>Whether a person who is using PyTorch for training models would benefit from switching to Functorch would depend on a number of factors, including their specific goals and the specific features of the two frameworks.</p><p>Functorch is a functional programming framework built on top of PyTorch, so it offers many of the same capabilities as PyTorch, such as support for deep learning and neural networks. However, Functorch also adds functional programming constructs, such as higher-order functions and automatic differentiation, which can make it easier to write concise, modular, and reusable code.</p><p>If a person is already familiar with PyTorch and is happy with the features and capabilities it offers, then switching to Functorch may not necessarily provide any significant benefits. However, if a person is looking for a way to improve the efficiency and modularity of their machine learning code, or if they are interested in using functional programming techniques in their work, then Functorch might be a good option to consider.</p><p>Ultimately, whether a person would benefit from switching from PyTorch to Functorch would depend on their specific needs and goals. It might be worth exploring both frameworks to see which one works best for a particular project or use case.</p><h2 id=can-you-give-me-an-example class="relative group">Can You Give Me an Example? <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#can-you-give-me-an-example aria-label=Anchor>#</a></span></h2><p>Here is an example of a simple machine learning model written in vanilla PyTorch:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> torch  
</span></span><span style=display:flex><span><span style=color:#75715e># Define a model with a single linear layer </span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>LinearModel</span>(torch<span style=color:#f92672>.</span>nn<span style=color:#f92672>.</span>Module):     
</span></span><span style=display:flex><span>	<span style=color:#66d9ef>def</span> __init__(self, input_size, output_size):         
</span></span><span style=display:flex><span>		super()<span style=color:#f92672>.</span>__init__()         
</span></span><span style=display:flex><span>		self<span style=color:#f92672>.</span>linear <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>nn<span style=color:#f92672>.</span>Linear(input_size, output_size)          
</span></span><span style=display:flex><span>	<span style=color:#66d9ef>def</span> <span style=color:#a6e22e>forward</span>(self, x):         
</span></span><span style=display:flex><span>		<span style=color:#66d9ef>return</span> self<span style=color:#f92672>.</span>linear(x)  
</span></span><span style=display:flex><span><span style=color:#75715e># Create an instance of the model </span>
</span></span><span style=display:flex><span>model <span style=color:#f92672>=</span> LinearModel(<span style=color:#ae81ff>10</span>, <span style=color:#ae81ff>1</span>)  
</span></span><span style=display:flex><span><span style=color:#75715e># Generate some random input data </span>
</span></span><span style=display:flex><span>x <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>randn(<span style=color:#ae81ff>100</span>, <span style=color:#ae81ff>10</span>)  
</span></span><span style=display:flex><span><span style=color:#75715e># Use the model to make predictions on the input data </span>
</span></span><span style=display:flex><span>y_pred <span style=color:#f92672>=</span> model(x)  
</span></span><span style=display:flex><span><span style=color:#75715e># Calculate the loss </span>
</span></span><span style=display:flex><span>loss <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>nn<span style=color:#f92672>.</span>functional<span style=color:#f92672>.</span>mse_loss(y_pred, y)  
</span></span><span style=display:flex><span><span style=color:#75715e># Backpropagate the loss to calculate the gradients </span>
</span></span><span style=display:flex><span>loss<span style=color:#f92672>.</span>backward()  
</span></span><span style=display:flex><span><span style=color:#75715e># Update the model parameters </span>
</span></span><span style=display:flex><span>optimizer <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>optim<span style=color:#f92672>.</span>SGD(model<span style=color:#f92672>.</span>parameters(), lr<span style=color:#f92672>=</span><span style=color:#ae81ff>0.01</span>) 
</span></span><span style=display:flex><span>optimizer<span style=color:#f92672>.</span>step()
</span></span></code></pre></div><p>Here is the same model written using Functorch:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> functorch <span style=color:#66d9ef>as</span> fc  
</span></span><span style=display:flex><span><span style=color:#75715e># Define a model with a single linear layer using Functorch&#39;s functional API</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>linear_model</span>(input_size, output_size):     
</span></span><span style=display:flex><span>	<span style=color:#66d9ef>def</span> <span style=color:#a6e22e>forward</span>(x):         
</span></span><span style=display:flex><span>		linear <span style=color:#f92672>=</span> fc<span style=color:#f92672>.</span>Linear(input_size, output_size)         
</span></span><span style=display:flex><span>		<span style=color:#66d9ef>return</span> linear(x)     
</span></span><span style=display:flex><span>	<span style=color:#66d9ef>return</span> fc<span style=color:#f92672>.</span>Model(forward)  
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Create an instance of the model</span>
</span></span><span style=display:flex><span>model <span style=color:#f92672>=</span> linear_model(<span style=color:#ae81ff>10</span>, <span style=color:#ae81ff>1</span>)  
</span></span><span style=display:flex><span><span style=color:#75715e># Generate some random input data </span>
</span></span><span style=display:flex><span>x <span style=color:#f92672>=</span> fc<span style=color:#f92672>.</span>randn(<span style=color:#ae81ff>100</span>, <span style=color:#ae81ff>10</span>)  
</span></span><span style=display:flex><span><span style=color:#75715e># Use the model to make predictions on the input data </span>
</span></span><span style=display:flex><span>y_pred <span style=color:#f92672>=</span> model(x)  
</span></span><span style=display:flex><span><span style=color:#75715e># Calculate the loss </span>
</span></span><span style=display:flex><span>loss <span style=color:#f92672>=</span> fc<span style=color:#f92672>.</span>mse_loss(y_pred, y)  
</span></span><span style=display:flex><span><span style=color:#75715e># Backpropagate the loss to calculate the gradients </span>
</span></span><span style=display:flex><span>loss<span style=color:#f92672>.</span>backward()  
</span></span><span style=display:flex><span><span style=color:#75715e># Update the model parameters </span>
</span></span><span style=display:flex><span>optimizer <span style=color:#f92672>=</span> fc<span style=color:#f92672>.</span>SGD(model<span style=color:#f92672>.</span>parameters(), lr<span style=color:#f92672>=</span><span style=color:#ae81ff>0.01</span>) 
</span></span><span style=display:flex><span>optimizer<span style=color:#f92672>.</span>step()
</span></span></code></pre></div><p>In this example, the model is defined using Functorch&rsquo;s functional API, which allows us to write the model as a function that takes inputs and returns outputs. This can make the code more concise and easier to read than the PyTorch version, which uses object-oriented programming. Additionally, Functorch automatically calculates gradients and performs backpropagation when <code>loss.backward()</code> is called, which can make the code even simpler and more modular.</p><h2 id=a-more-complicated-example class="relative group">A More Complicated Example <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#a-more-complicated-example aria-label=Anchor>#</a></span></h2><p>Sure, here is a more complicated example of a machine learning model written using Functorch:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> functorch <span style=color:#66d9ef>as</span> fc  
</span></span><span style=display:flex><span><span style=color:#75715e># Define a convolutional neural network using Functorch&#39;s functional API </span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>convnet</span>(input_size, num_classes):     
</span></span><span style=display:flex><span>	<span style=color:#66d9ef>def</span> <span style=color:#a6e22e>forward</span>(x):         
</span></span><span style=display:flex><span>		<span style=color:#75715e># Apply a sequence of convolutional and pooling layers         </span>
</span></span><span style=display:flex><span>		x <span style=color:#f92672>=</span> fc<span style=color:#f92672>.</span>Conv2d(x, <span style=color:#ae81ff>32</span>, kernel_size<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span>, padding<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>)         
</span></span><span style=display:flex><span>		x <span style=color:#f92672>=</span> fc<span style=color:#f92672>.</span>ReLU(x)         
</span></span><span style=display:flex><span>		x <span style=color:#f92672>=</span> fc<span style=color:#f92672>.</span>MaxPool2d(x, kernel_size<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>)         
</span></span><span style=display:flex><span>		x <span style=color:#f92672>=</span> fc<span style=color:#f92672>.</span>Conv2d(x, <span style=color:#ae81ff>64</span>, kernel_size<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span>, padding<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>)         
</span></span><span style=display:flex><span>		x <span style=color:#f92672>=</span> fc<span style=color:#f92672>.</span>ReLU(x)         
</span></span><span style=display:flex><span>		x <span style=color:#f92672>=</span> fc<span style=color:#f92672>.</span>MaxPool2d(x, kernel_size<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>)          
</span></span><span style=display:flex><span>		<span style=color:#75715e># Flatten the output of the convolutional layers         </span>
</span></span><span style=display:flex><span>		x <span style=color:#f92672>=</span> x<span style=color:#f92672>.</span>view(x<span style=color:#f92672>.</span>size(<span style=color:#ae81ff>0</span>), <span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>)          
</span></span><span style=display:flex><span>		<span style=color:#75715e># Apply a sequence of fully-connected layers         </span>
</span></span><span style=display:flex><span>		x <span style=color:#f92672>=</span> fc<span style=color:#f92672>.</span>Linear(x, <span style=color:#ae81ff>512</span>)         
</span></span><span style=display:flex><span>		x <span style=color:#f92672>=</span> fc<span style=color:#f92672>.</span>ReLU(x)         
</span></span><span style=display:flex><span>		x <span style=color:#f92672>=</span> fc<span style=color:#f92672>.</span>Linear(x, num_classes)          
</span></span><span style=display:flex><span>		<span style=color:#75715e># Return the logits         </span>
</span></span><span style=display:flex><span>		<span style=color:#66d9ef>return</span> x      
</span></span><span style=display:flex><span>	<span style=color:#66d9ef>return</span> fc<span style=color:#f92672>.</span>Model(forward)  
</span></span><span style=display:flex><span><span style=color:#75715e># Create an instance of the model </span>
</span></span><span style=display:flex><span>model <span style=color:#f92672>=</span> convnet(input_size<span style=color:#f92672>=</span>(<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>32</span>, <span style=color:#ae81ff>32</span>), num_classes<span style=color:#f92672>=</span><span style=color:#ae81ff>10</span>)  
</span></span><span style=display:flex><span><span style=color:#75715e># Generate some random input data </span>
</span></span><span style=display:flex><span>x <span style=color:#f92672>=</span> fc<span style=color:#f92672>.</span>randn(<span style=color:#ae81ff>100</span>, <span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>32</span>, <span style=color:#ae81ff>32</span>)  
</span></span><span style=display:flex><span><span style=color:#75715e># Use the model to make predictions on the input data </span>
</span></span><span style=display:flex><span>y_pred <span style=color:#f92672>=</span> model(x)  
</span></span><span style=display:flex><span><span style=color:#75715e># Calculate the loss </span>
</span></span><span style=display:flex><span>loss <span style=color:#f92672>=</span> fc<span style=color:#f92672>.</span>cross_entropy_loss(y_pred, y)  
</span></span><span style=display:flex><span><span style=color:#75715e># Backpropagate the loss to calculate the gradients </span>
</span></span><span style=display:flex><span>loss<span style=color:#f92672>.</span>backward()  
</span></span><span style=display:flex><span><span style=color:#75715e># Update the model parameters </span>
</span></span><span style=display:flex><span>optimizer <span style=color:#f92672>=</span> fc<span style=color:#f92672>.</span>SGD(model<span style=color:#f92672>.</span>parameters(), lr<span style=color:#f92672>=</span><span style=color:#ae81ff>0.01</span>) optimizer<span style=color:#f92672>.</span>step()
</span></span></code></pre></div><p>In this example, we define a convolutional neural network using Functorch&rsquo;s functional API. This allows us to write the model as a function that takes inputs and returns outputs, and it allows us to use functional programming constructs such as higher-order functions and automatic differentiation. This can make the code more concise and easier to read than if we were to define the model using object-oriented programming, as we would have to do in PyTorch.</p><p>Additionally, Functorch automatically calculates gradients and performs backpropagation when <code>loss.backward()</code> is called, which can make the code even simpler and more modular. This can be particularly useful when working with complex neural network architectures, as it can help reduce the amount of boilerplate code that needs to be written.</p><h2 id=making-my-conversation-into-a-blog-post class="relative group">Making My Conversation into a Blog Post? <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#making-my-conversation-into-a-blog-post aria-label=Anchor>#</a></span></h2><blockquote><p>Q: How would our conversation until here look like as a blog post?</p></blockquote><p>Here is an example of how our conversation until now could be written as a blog post:</p><p><strong>Title: Functional Programming in Machine Learning: An Introduction to Functorch and JAX</strong></p><p>Functional programming is a programming paradigm that focuses on the use of functions to model computations and data. In recent years, functional programming has been gaining popularity in the machine learning community, with some frameworks, such as Functorch and JAX, adopting functional programming paradigms.</p><p>Functorch is a functional programming framework built on top of PyTorch, a popular deep learning library. It allows users to write code using functional programming constructs, such as higher-order functions and automatic differentiation, which can make it easier to write concise, modular, and reusable code.</p><p>JAX is another functional programming framework for machine learning, built on top of the NumPy library. Like Functorch, it allows users to write code using functional programming constructs and to perform automatic differentiation. Additionally, JAX can run on GPUs and other hardware accelerators, which can make it easier to scale up machine learning code and work with large datasets.</p><p>The use of functional programming in machine learning is still relatively new, but it is gaining traction as a way to improve the efficiency and modularity of machine learning code. If you are interested in functional programming and machine learning, then learning about Functorch and JAX could be a useful addition to your skillset.</p></div></section><footer class="max-w-prose pt-8 print:hidden"><div class=flex><div class=place-self-center><div class="text-2xl sm:text-lg"></div></div></div><div class=pt-8><hr class="border-dotted border-neutral-300 dark:border-neutral-600"><div class="flex justify-between pt-3"><span><a class="group flex" href=/posts/2022-11-17-information-proc-org-rec/><span class="me-2 text-neutral-700 transition-transform group-hover:-translate-x-[2px] group-hover:text-primary-600 dark:text-neutral dark:group-hover:text-primary-400"><span class="ltr:inline rtl:hidden">&larr;</span><span class="ltr:hidden rtl:inline">&rarr;</span></span>
<span class="flex flex-col"><span class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500">Information- Processing, Organization and Retrieval</span>
<span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400"><time datetime="2022-11-17 17:11:30 +0800 +0800">17 November 2022</time>
</span></span></a></span><span><a class="group flex text-right" href=/posts/2023-02-01-mlaas-vs-mlops/><span class="flex flex-col"><span class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500">MLaaS vs MLOps</span>
<span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400"><time datetime="2023-02-01 10:48:39 +0800 +0800">1 February 2023</time>
</span></span><span class="ms-2 text-neutral-700 transition-transform group-hover:-translate-x-[2px] group-hover:text-primary-600 dark:text-neutral dark:group-hover:text-primary-400"><span class="ltr:inline rtl:hidden">&rarr;</span><span class="ltr:hidden rtl:inline">&larr;</span></span></a></span></div></div></footer></article><div class="pointer-events-none absolute bottom-0 end-0 top-[100vh] w-12"><a href=#the-top class="pointer-events-auto sticky top-[calc(100vh-5.5rem)] flex h-12 w-12 items-center justify-center rounded-full bg-neutral/50 text-xl text-neutral-700 backdrop-blur hover:text-primary-600 dark:bg-neutral-800/50 dark:text-neutral dark:hover:text-primary-400" aria-label="Scroll to top" title="Scroll to top">&uarr;</a></div></main><footer class="py-10 print:hidden"><div class="flex items-center justify-between"><div><p class="text-sm text-neutral-500 dark:text-neutral-400">&copy;
2024</p><p class="text-xs text-neutral-500 dark:text-neutral-400">Powered by <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500" href=https://gohugo.io/ target=_blank rel="noopener noreferrer">Hugo</a> & <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500" href=https://github.com/jpanther/congo target=_blank rel="noopener noreferrer">Congo</a></p></div><div class="flex flex-row items-center"></div></div></footer></div></body></html>